#!/usr/bin/env python

#Importing Libraries
import cv2
import rospy
import time
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from tensorflow.keras.applications import ResNet50
from imutils.object_detection import non_max_suppression
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions

#Defining the bridge
bridge = CvBridge()

# load ResNet from disk (with weights pre-trained on ImageNet)
print("[INFO] loading ResNet...")
model = ResNet50(weights="imagenet")

# grab the label filters command line argument
labelFilters = None

# if the label filter is not empty, break it into a list
if labelFilters is not None:
	labelFilters = labelFilters.lower().split(",")

#Function to find the objects in the image
def selective_search(image, method="fast"):
	# initialize OpenCV's selective search implementation and set the
	# input image
	ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
	ss.setBaseImage(image)
	# check to see if we are using the *fast* but *less accurate* version of selective search
	if method == "fast":
		ss.switchToSelectiveSearchFast()
	# otherwise we are using the *slower* but *more accurate* version
	else:
		ss.switchToSelectiveSearchQuality()
	# run selective search on the input image
	rects = ss.process()
	# return the region proposal bounding boxes
	return rects

#Function to make predictions
def prediction(image):
    # load the input image from disk and grab its dimensions
    start_time = time.time()
    #Storing the height and width of the original image
    (H, W) = image.shape[:2]
    # run selective search on the input image
    rects = selective_search(image, method="")
    print("Rectangles aare there")
    # initialize the list of region proposals that we'll be classifyin along with their associated bounding boxes
    proposals = []
    boxes = []
    # loop over the region proposal bounding box coordinates generated by running selective search
    for (x, y, w, h) in rects:
    	# filtering out small objects
    	if w / float(W) < 0.1 or h / float(H) < 0.1:
    		continue

    	# extract the region from the input image, convert it from BGR to
    	# RGB channel ordering, and then resize it to 224x224 (the input
    	# dimensions required by our pre-trained CNN)
    	roi = image[y:y + h, x:x + w]
    	roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    	roi = cv2.resize(roi, (224, 224))

    	# further preprocess by the ROI
    	roi = img_to_array(roi)
    	roi = preprocess_input(roi)

    	# update our proposals and bounding boxes lists
    	proposals.append(roi)
    	boxes.append((x, y, w, h))

    # convert the proposals list into NumPy array and show its dimensions
    proposals = np.array(proposals)

    # classify each of the proposal ROIs using ResNet and then decode the predictions
    preds = model.predict(proposals)
    preds = decode_predictions(preds, top=1)

    # initialize a dictionary which maps class labels (keys) to any bounding box associated with that label (values)
    labels = {}

    # loop over the predictions
    for (i, p) in enumerate(preds):
    	# grab the prediction information for the current region proposal
    	(imagenetID, label, prob) = p[0]

    	# only if the label filters are not empty *and* the label does not exist in the list, then ignore it
    	if labelFilters is not None and label not in labelFilters:
    		continue

    	# filtering out weak detections
    	if prob >=  0.5:
    		# grab the bounding box associated with the prediction and convert the coordinates
    		(x, y, w, h) = boxes[i]
    		box = (x, y, x + w, y + h)

    		# grab the list of predictions for the label and add the bounding box + probability to the list
    		L = labels.get(label, [])
    		L.append((box, prob))
    		labels[label] = L

    # loop over the labels for each of detected objects in the image
    for label in labels.keys():
    	# clone the original image so that we can draw on it
    	end_time = time.time()
    	print("Inference time: ", end_time-start_time)
    	print("[INFO] showing results for '{}'".format(label))
    	clone = image.copy()

    	# extract the bounding boxes and associated prediction probabilities, then apply non-maxima suppression
    	boxes = np.array([p[0] for p in labels[label]])
    	proba = np.array([p[1] for p in labels[label]])
    	boxes = non_max_suppression(boxes, proba)

    	# loop over all bounding boxes that were kept after applying non-maxima suppression
    	for (startX, startY, endX, endY) in boxes:
    		# draw the bounding box and label on the image
    		#cv2.rectangle(clone, (startX, startY), (endX, endY),(0, 255, 0), 2)
    		#y = startY - 10 if startY - 10 > 10 else startY + 10
    		#cv2.putText(clone, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)
            print("Label is", label)

    	# show the output after apply non-maxima suppression
    	cv2.imshow("After", clone)
    	cv2.waitKey(3)

#Callback Function
def callback(data):
    try:
        #Converting to CV2 Image
        cv_img = bridge.imgmsg_to_cv2(data, "bgr8")
        #Diplaying the image
        #cv2.imshow("Picture", cv_img)
        #cv2.waitKey(3)
        #Object detection
        print("Started Prediciton")
        prediction(cv_img)

    except CvBridgeError as e:
        print(e)

#Main Function
def main():
    #Initialzing the node
    rospy.init_node("Image_processing", anonymous=True)
    #Subscribing the image
    rospy.Subscriber("/rrbot/camera1/image_raw", Image, callback)
    #Updating the master
    rospy.spin()

#Calling the main thread
if __name__ == "__main__":
    main()
